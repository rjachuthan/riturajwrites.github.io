---
title: I don't want my AI Image Generators to be Inclusive!
description: Exploring the balance between AI image generators and inclusivity. Understand the challenges of enforcing inclusivity.
aliases:
  - Why You Should Not Expect Your Image Generation AI To Throw Diverse Results
  - I don't want my AI Image Generators to be Inclusive!
tags:
  - üåøbudding
  - generativeai
  - üì¢opinion
  - image
draft: false
date: 2024-05-28
backlink:
  - "[[image generation tools|Image Generation Tools]]"
---

For the past couple of days, there's been a slow-burn conversation in a group chat about how an Image Generation AI - [Kalaido.ai](kalaido.ai) - isn't being "inclusive." Someone started a thread questioning why [[generative ai|image generation tools]] like Kalaido, ChatGPT, and DALL-E 3 don't generate images of women when asked to create an *"image of an Indian coder working in an office."* This was a genuine query from the user and not a political statement. While some colleagues agree and want more inclusivity from the [[artificial intelligence|AI]], I see things a bit differently.

[^1] ![[banner_confused robot painting on canvas by ideogram-ai.png]]

First off, let me clarify few things:
- These thoughts are specific to the discussion of AI inclusivity and diversity. I hope you won't misinterpret this as my stance on inclusivity and diversity in general.
- I am in no way involved with the any of the Image Generation AIs discussed in this article.

Here‚Äôs the deal: AI Image Generators like [Kalaido AI](https://kalaido.ai/), [ChatGPT](https://chatgpt.com), [Midjourney](https://www.midjourney.com/home), [Stable Diffusion](https://github.com/Stability-AI/stablediffusion), [Leonardo.ai](https://leonardo.ai/), [Ideogram](https://ideogram.ai/), and others operate based on the training data they‚Äôre fed. These datasets tend to reflect real-world patterns if no specific agenda is followed. So, if there are more male coders than female coders in the real world[^2], the training data will mirror this pattern. This is just basic statistics - if there are more images of male coders in the training set, the AI is more likely to generate an image of a male coder. If you want an image of a female coder, you need to ask for it specifically. Expecting the AI to read your mind is bad [[prompt engineering|prompting]] - more of a "Skill Issue" than an [[artificial intelligence|AI]] issue.

Now, I‚Äôm not saying it‚Äôs impossible for companies to aim for diversity and inclusivity in their [[artificial intelligence|AI]]. It‚Äôs just that those who try, will have to go out of their way to implement this feature, which can be a bit of a fool's errand. A few months back, [Google's Gemini](https://gemini.google.com/) attempted to force inclusivity in its image generator AI, and it didn't go well. The AI ended up inserting forced "agendas" or inclusiveness, leading to backlash.[^3] What I learned from this incident is that political correctness can be a never-ending game - please one group, and another gets offended. 

## My Naive Solution for AI Inclusivity

Why not have the [[artificial intelligence|AI]] check assumptions with the user before generating the image? Some AI image generators already use [[LLMs]] to fine-tune user prompts before generating images.[^4] This step gives users full control and shifts the responsibility of being politically correct from the [[artificial intelligence|AI]] to the user. The flow would look something like this:

![[img_20240527 gen ai - user prompt flow.svg|center]]

It might seem naive, but this approach could help AI Image Generators and the companies behind them avoid the blame on them. I just want these wonderful companies to keep working on making these models wonderful, instead of focusing on things that derail them from producing such wonderful works.

In conclusion, in my eyes, AI inclusivity is a complex issue with no easy solution. While my suggestion might be simplistic, it‚Äôs a step toward balancing user expectations with the capabilities of AI.

[^1]: Image Generated by [Ideogram.ai](ideogram.ai) using a prompt: "a watercolor image of a confused robot trying to paint, question marks floating over its head". If you have Ideogram account, you can access the image [here](https://ideogram.ai/g/OjCYK2O8TW6Y2w6cdGBefA/1).
[^2]: ‚ÄúThe software development industry is dominated by men (91.88%), while the minority is comprised of women (5.17%) and non-binary, genderqueer, or non-conforming (1.67%)‚Äù: [Source: Software developer statistics you should know in 2024](https://www.outsourceaccelerator.com/articles/software-developer-statistics/)
[^3]: [How NOT to Embrace Diversity in AI Development? Reflecting on Google‚Äôs Gemini Debacle](https://medium.com/@narayan.somendra/how-not-to-embrace-diversity-in-ai-development-reflecting-on-the-gemini-debacle-2c869f7257ad) by "Somendra Narayan"
[^4]: While creating the title image [^1] using [Ideogram](ideogram.ai), I have gave a prompt saying: "a watercolor image of a confused robot trying to paint, question marks floating over its head". This prompt was changed by Ideogram to something they call as **Magic Prompt**: "A whimsical watercolor painting of a confused robot, seemingly unsure of its artistic abilities. The robot, with gears and metal accents, is holding a paintbrush and a palette, while question marks float above its head. It stands in front of a canvas with a splash of colors, indicating its recent attempts at painting. The background is a charming mix of soft blues and greens, bringing a serene atmosphere to the scene." If you have Ideogram account, you can access the image [here](https://ideogram.ai/g/OjCYK2O8TW6Y2w6cdGBefA/1).
